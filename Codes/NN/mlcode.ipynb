{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9236509,"sourceType":"datasetVersion","datasetId":5514547},{"sourceId":9650104,"sourceType":"datasetVersion","datasetId":5849856}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n# Load the CSV file into a pandas DataFrame\ndf = pd.read_csv('/kaggle/input/new-compressor-data/combined_file_ap_500.csv')  #the respective csv file for the corresponding cluster size can be loaded here\n\n# the weights obtained using the 500 cluster size file are later used to test the model on other datasets\n\n# first few rows of the DataFrame\nprint(df.head())\n\n# basic data exploration\nprint(df.info())\nprint(df.describe())\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for missing values\nprint(df.isnull().sum())\n\n#  dropping\ndf = df.dropna()\n\n# Separating features and target variable 'Multiplier'\nX = df.drop(columns=['Multiplier', 'Area', 'Power']).values\ny = df['Multiplier'].values\n\nprint(\"Unique multipliers:\", df['Multiplier'].value_counts())\n\n# Encoding categorical target variable 'Multiplier' to numeric labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Normalizing the features\nscaler = StandardScaler()\nX_normalized = scaler.fit_transform(X)\n\n# Dataset split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y_encoded, test_size=0.2, random_state=42)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The neural network model \nmodel = Sequential()\n\n# Input layer\nmodel.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n\n# Additional hidden layers\nmodel.add(Dense(128, activation='gelu'))\nmodel.add(Dense(64, activation='gelu'))\nmodel.add(Dense(64, activation='gelu'))\nmodel.add(Dense(32, activation='gelu'))\n\n# Output layer\nnum_classes = len(set(y_encoded))  # Number of unique classes\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Early stopping callback\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=70, restore_best_weights=True, verbose=1)\n\n# Training the model with early stopping\nhistory = model.fit(X_train, y_train, epochs=1500, batch_size=32, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n\n#  Model weights saved after training\nmodel.save_weights('model.weights.h5')\nprint(\"Model weights saved successfully.\")\n\n# Custom evaluation function\ndef custom_evaluate(model, X_test, y_test, label_encoder):\n    # Get the predicted probabilities from the model\n    y_pred_probs = model.predict(X_test)\n    \n    # Converting predicted probabilities to class labels\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    \n    # Decoding the predicted and actual labels (if using encoded labels)\n    y_pred_decoded = label_encoder.inverse_transform(y_pred)\n    y_test_decoded = label_encoder.inverse_transform(y_test)\n    \n    # Calculating custom accuracy based on conditions\n    correct = 0\n    ssim_diff = 0.01\n    cost_diff = 1\n    for i in range(len(y_test)):\n        for j in range(len(y_pred)):\n            if abs(X_test[j][0] - X_test[i][0]) <= ssim_diff and abs(X_test[j][1] - X_test[i][1]) <= cost_diff:\n                if y_pred[i] == y_test[j]:\n                    correct += 1\n                    break\n    \n    accuracy = correct / len(y_pred)\n    \n    \n    print(\"Final Test Accuracy:\", accuracy)\n    return accuracy\n\n\nloss, accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint(\"Exact Test Accuracy: {accuracy:.4f}\")\n\n\n# Calling the custom evaluation function on the test set\ncustom_accuracy = custom_evaluate(model, X_test, y_test, label_encoder)\n\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# cluster sizes for the dataset\nsizes = [ 2000, 3000, 4000]\n\n\n# Iterating over all sizes to evaluate each corresponding dataset\nfor size in sizes:\n    # Loading the new dataset for testing corresponding to the current cluster size\n    csv_file = f'/kaggle/input/mnist-data/combined_file_ap_{size}.csv'\n    new_df = pd.read_csv(csv_file)\n\n    # Preprocessing the new dataset (similar to the training dataset)\n    new_df = new_df.dropna()\n\n    # Separation of features and target variable 'Multiplier'\n    X_new = new_df.drop(columns=['Multiplier', 'Area', 'Power']).values\n    y_new = new_df['Multiplier'].values\n\n    # Combining old and new labels for the LabelEncoder\n    combined_labels = np.concatenate((y, y_new))\n\n    # Re-fitting the LabelEncoder with the combined labels\n    label_encoder.fit(combined_labels)\n\n    # Encoding the new labels\n    y_new_encoded = label_encoder.transform(y_new)\n\n    # Normalizing the features of the new dataset\n    X_new_normalized = scaler.transform(X_new)\n\n    # Loading the saved model weights\n    model.load_weights('model.weights.h5')\n    print(f\"Model weights loaded successfully for size {size}.\")\n\n    # Test the model on the new data with updated labels\n    custom_accuracy_new = custom_evaluate(model, X_new_normalized, y_new_encoded, label_encoder)\n    print(f\"Custom accuracy on the new test dataset (size {size}): {custom_accuracy_new}\")\n\n    # Predicting class labels for the new data\n    y_new_pred_encoded = model.predict(X_new_normalized)\n\n    # Converting the predicted probabilities to class labels\n    y_new_pred = np.argmax(y_new_pred_encoded, axis=1)\n\n    # Calculating normal accuracy\n    normal_accuracy_new = accuracy_score(y_new_encoded, y_new_pred)\n    print(f\"Normal accuracy on the new dataset (size {size}): {normal_accuracy_new}\")\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}